{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# keep columns that are relevant\n",
    "\n",
    "data_directory = 'data/'\n",
    "filename = 'states_2017-08-28-00.csv'\n",
    "\n",
    "usecols=['time','icao24','lat','lon','velocity','heading','baroaltitude']\n",
    "month_df = pd.read_csv(data_directory + filename, usecols=usecols)\n",
    "month_df = month_df.sort_values(['icao24','time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generates one big CSV file of NMAC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old code that was used to generate CSVs of a flight path for each plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import geopy\n",
    "import geopy.distance\n",
    "\n",
    "def compute_distance(point_1, point_2):\n",
    "    '''    \n",
    "    Parameters:\n",
    "        - point_1 -> list in order of [lat,long, alt]\n",
    "        - point_2 -> list in order of [lat,long, alt]\n",
    "        \n",
    "    Returns:\n",
    "        Distance between two points in km using geopy\n",
    "    '''    \n",
    "    p1 = geopy.point.Point(point_1)\n",
    "    p2 = geopy.point.Point(point_2)\n",
    "\n",
    "    return geopy.distance.vincenty(p1, p2).km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c8145d1a51ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saved files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mgen_NMAC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-c8145d1a51ea>\u001b[0m in \u001b[0;36mgen_NMAC\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgen_NMAC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# get rows that were in an NMAC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mNMAC_icao\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# get rows that were in an NMAC and have readily available data (i.e. remove rows with NaN for lat long etc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcleaned_NMAC_icao\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNMAC_icao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# generating NMAC data\n",
    "def gen_NMAC():\n",
    "    # get rows that were in an NMAC\n",
    "    NMAC_icao = df[df['alert'] == True]\n",
    "    # get rows that were in an NMAC and have readily available data (i.e. remove rows with NaN for lat long etc)\n",
    "    cleaned_NMAC_icao = NMAC_icao.dropna()\n",
    "    unique_NMAC_icao = cleaned_NMAC_icao.icao24.unique()\n",
    "    \n",
    "\n",
    "    print('There are {} unique potential NMAC icao planes'.format(len(unique_NMAC_icao)))\n",
    "    count = 0\n",
    "    \n",
    "    # ultimate final NMAC csv dataframe\n",
    "    df_final = pd.DataFrame()\n",
    " \n",
    "    NMAC_id = 0\n",
    "    # for each unique icao\n",
    "    for name in unique_NMAC_icao:\n",
    "        # print stats\n",
    "        if count % 100 == 0:\n",
    "            print('Iterated through {} icao planes so far...'.format(count))\n",
    "        count += 1\n",
    "        # get rows where icao == name (boolean vector)\n",
    "        selector = cleaned_NMAC_icao['icao24'] == name\n",
    "        current_icao = cleaned_NMAC_icao[selector]\n",
    "\n",
    "        for second_name in unique_NMAC_icao:\n",
    "            second_selector = cleaned_NMAC_icao['icao24'] == second_name\n",
    "            second_icao = cleaned_NMAC_icao[second_selector]\n",
    "\n",
    "            if name == second_name:\n",
    "                continue\n",
    "\n",
    "            incremented_NMAC_id = False\n",
    "            for index, row in current_icao.iterrows():\n",
    "                for index2, row2 in second_icao.iterrows():\n",
    "                    lat_1 = row['lat']\n",
    "                    lon_1 = row['lon']\n",
    "                    alt_1 = row['baroaltitude']\n",
    "\n",
    "                    lat_2 = row2['lat']\n",
    "                    lon_2 = row2['lon']\n",
    "                    alt_2 = row2['baroaltitude']\n",
    "\n",
    "                    point_1 = [lat_1, lon_1, alt_1]\n",
    "                    point_2 = [lat_2, lon_2, alt_2]\n",
    "\n",
    "                    dist = compute_distance(point_1, point_2)\n",
    "\n",
    "                    if dist < 200 and row['time'] == row2['time']:\n",
    "                        if not incremented_NMAC_id:\n",
    "                            NMAC_id += 1\n",
    "                            incremented_NMAC_id = True\n",
    "                        \n",
    "                        NMAC_row = pd.DataFrame({\n",
    "                            'NMAC_id': [NMAC_id],\n",
    "                            'time_1': [row['time']], #first plane\n",
    "                            'icao24_1':[row['icao24']],\n",
    "                            'lat_1':[row['lat']],\n",
    "                            'lon_1':[row['lon']],\n",
    "                            'velocity_1':[row['velocity']],\n",
    "                            'heading_1':[row['heading']],\n",
    "                            'vertrate_1':[row['vertrate']],\n",
    "                            'onground_1':[row['onground']],\n",
    "                            'alert_1':[row['alert']],\n",
    "                            'baroaltitude_1':[row['baroaltitude']],\n",
    "                            'lastposupdate_1':[row['lastposupdate']],\n",
    "                            'lastcontact_1':[row['lastcontact']],\n",
    "                            'time_2': [row2['time']], #second plane\n",
    "                            'icao24_2':[row2['icao24']],\n",
    "                            'lat_2':[row2['lat']],\n",
    "                            'lon_2':[row2['lon']],\n",
    "                            'velocity_2':[row2['velocity']],\n",
    "                            'heading_2':[row2['heading']],\n",
    "                            'vertrate_2':[row2['vertrate']],\n",
    "                            'onground_2':[row2['onground']],\n",
    "                            'alert_2':[row2['alert']],\n",
    "                            'baroaltitude_2':[row2['baroaltitude']],\n",
    "                            'lastposupdate_2':[row2['lastposupdate']],\n",
    "                            'lastcontact_2':[row2['lastcontact']],\n",
    "                            })\n",
    "                        # add to data frame\n",
    "                        df_final = df_final.append(NMAC_row)\n",
    "\n",
    "    # write to csv file\n",
    "    df_final.to_csv(\"NMAC.csv\".format(name), index=False)\n",
    "    print('Saved files')\n",
    "\n",
    "gen_NMAC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique icao (unique plane IDs)\n",
    "unique_icao = df.icao24.unique()\n",
    "print(unique_icao, len(unique_icao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generating CSVs for flight path data for each plane (might not be used)\n",
    "# num_unique = len(unique_icao)\n",
    "\n",
    "csv_count = 0\n",
    "iteration = 0\n",
    "# for each unique icao, create CSV for it\n",
    "for name in unique_icao:\n",
    "    # print stats\n",
    "    if iteration % 500 == 0:\n",
    "        print('Iterated through {} icao names'.format(iteration))\n",
    "    iteration +=1\n",
    "    \n",
    "    # get rows where icao == name (boolean vector)\n",
    "    selector = df['icao24'] == name\n",
    "    \n",
    "    # Make sure columns have data, otherwise skip\n",
    "    if (df[selector].isnull().values.any()):\n",
    "        continue\n",
    "    \n",
    "    # print stats\n",
    "    if csv_count % 100 == 0:\n",
    "        print('Wrote {} csvs files'.format(csv_count))\n",
    "    csv_count += 1\n",
    "    \n",
    "    # write only rows to csv where the vector is true:\n",
    "    df[selector].to_csv(\"cleaned/{}.csv\".format(name), index=False)\n",
    "    \n",
    "print('Done')\n",
    "print('Saved {} csv files'.format(csv_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean month_df, add cols for displacement instead of lat and lon, save to csv for simple RNN network input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique icao (unique plane IDs)\n",
    "unique_icao = df.icao24.unique()\n",
    "print(unique_icao, len(unique_icao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make df and write to csv\n",
    "\n",
    "# final csv dataframe\n",
    "df_final = pd.DataFrame()\n",
    "\n",
    "iteration = 0\n",
    "# for each unique icao, create CSV for it\n",
    "for name in unique_icao:\n",
    "    # print stats\n",
    "    if iteration % 100 == 0:\n",
    "        print('Iterated through {} icao names'.format(iteration))\n",
    "    iteration +=1\n",
    "    \n",
    "    # get rows where icao == name (boolean vector)\n",
    "    selector = month_df['icao24'] == name\n",
    "    one_plane_df = month_df[selector]\n",
    "    \n",
    "    # Make sure columns have data, otherwise skip plane\n",
    "    if (one_plane_df.isnull().values.any()):\n",
    "        continue\n",
    "    \n",
    "    # calculate displacement columns\n",
    "\n",
    "    # add first row with 0s for displacement columns\n",
    "    first_row = one_plane_df.iloc[0]\n",
    "    prev_lat = first_row['lat']\n",
    "    prev_lon = first_row['lon']\n",
    "\n",
    "    row_prime = pd.DataFrame({\n",
    "            'time': [first_row['time']], \n",
    "            'icao24':[first_row['icao24']],\n",
    "            'x_displacement':[0],\n",
    "            'y_displacement':[0],\n",
    "            'velocity':[first_row['velocity']],\n",
    "            'heading':[first_row['heading']],\n",
    "            'baroaltitude':[first_row['baroaltitude']]\n",
    "    })\n",
    "\n",
    "    df_final = df_final.append(row_prime)\n",
    "\n",
    "    # for all except for first row, calculate displacement based on previous row's lat and lon\n",
    "    for index, row in islice(one_plane_df.iterrows(), 1, None):\n",
    "        curr_lat = row['lat']\n",
    "        curr_lon = row['lon']\n",
    "\n",
    "        # compute distance for lat and then lon\n",
    "        x_disp = curr_lon - prev_lon\n",
    "        y_disp = curr_lat - prev_lat\n",
    "\n",
    "        # save curr lat and lon as prev for next iteration\n",
    "        prev_lat = curr_lat\n",
    "        prev_lon = curr_lon\n",
    "\n",
    "        # add the row\n",
    "        row_prime = pd.DataFrame({\n",
    "            'time': [row['time']], \n",
    "            'icao24':[row['icao24']],\n",
    "            'x_displacement':[x_disp],\n",
    "            'y_displacement':[y_disp],\n",
    "            'velocity':[row['velocity']],\n",
    "            'heading':[row['heading']],\n",
    "            'baroaltitude':[row['baroaltitude']]\n",
    "        })\n",
    "\n",
    "        df_final = df_final.append(row_prime)\n",
    "\n",
    "print('Shape of df_final: {}'.format(df_final.shape))    \n",
    "\n",
    "\n",
    "# write to file\n",
    "\n",
    "clean_dir = 'cleaned/'\n",
    "if not os.path.exists(clean_dir):\n",
    "    os.makedirs(clean_dir)\n",
    "    \n",
    "# write only rows to csv where the vector is true:\n",
    "df_final.to_csv(clean_dir+'{}'.format(filename), index=False)\n",
    "    \n",
    "print('Saved file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just write to file\n",
    "\n",
    "clean_dir = 'cleaned/'\n",
    "if not os.path.exists(clean_dir):\n",
    "    os.makedirs(clean_dir)\n",
    "    \n",
    "# write only rows to csv where the vector is true:\n",
    "df_final.to_csv(clean_dir+'{}'.format(filename), index=False)\n",
    "    \n",
    "print('Saved file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding data\n",
    "\n",
    "After submitting our initial finding results, we now need to collect data and pad the data in such a way that each training example has the same number of sequence lengths (of size BATCH_SIZE). We need to do this because PyTorch and TensorFlow need to have inputs of same sequence length. Each training example is placed in the same csv.\n",
    "\n",
    "First, iterate through each icao, get data points where there was a nonzero displacement between two time steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 15 # length of training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00741d' '008fff' '00fee0' ..., 'e8407d' 'e90d0b' 'e90d0f'] 6097\n"
     ]
    }
   ],
   "source": [
    "# get unique icao (unique plane IDs)\n",
    "unique_icao = month_df.icao24.unique()\n",
    "print(unique_icao, len(unique_icao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterated through 0 icao names\n",
      "Iterated through 100 icao names\n",
      "Iterated through 200 icao names\n",
      "Iterated through 300 icao names\n",
      "Iterated through 400 icao names\n",
      "Iterated through 500 icao names\n",
      "Iterated through 600 icao names\n",
      "Iterated through 700 icao names\n",
      "Iterated through 800 icao names\n",
      "Iterated through 900 icao names\n",
      "Iterated through 1000 icao names\n",
      "Iterated through 1100 icao names\n",
      "Iterated through 1200 icao names\n",
      "Iterated through 1300 icao names\n",
      "Iterated through 1400 icao names\n",
      "Iterated through 1500 icao names\n",
      "Iterated through 1600 icao names\n",
      "Iterated through 1700 icao names\n",
      "Iterated through 1800 icao names\n",
      "Iterated through 1900 icao names\n",
      "Iterated through 2000 icao names\n",
      "Iterated through 2100 icao names\n",
      "Iterated through 2200 icao names\n",
      "Iterated through 2300 icao names\n",
      "Iterated through 2400 icao names\n",
      "Iterated through 2500 icao names\n",
      "Iterated through 2600 icao names\n",
      "Iterated through 2700 icao names\n",
      "Iterated through 2800 icao names\n",
      "Iterated through 2900 icao names\n",
      "Iterated through 3000 icao names\n",
      "Iterated through 3100 icao names\n",
      "Iterated through 3200 icao names\n",
      "Iterated through 3300 icao names\n",
      "Iterated through 3400 icao names\n",
      "Iterated through 3500 icao names\n",
      "Iterated through 3600 icao names\n",
      "Iterated through 3700 icao names\n",
      "Iterated through 3800 icao names\n",
      "Iterated through 3900 icao names\n",
      "Iterated through 4000 icao names\n",
      "Iterated through 4100 icao names\n",
      "Iterated through 4200 icao names\n",
      "Iterated through 4300 icao names\n",
      "Iterated through 4400 icao names\n",
      "Iterated through 4500 icao names\n",
      "Iterated through 4600 icao names\n",
      "Iterated through 4700 icao names\n",
      "Iterated through 4800 icao names\n",
      "Iterated through 4900 icao names\n",
      "Iterated through 5000 icao names\n",
      "Iterated through 5100 icao names\n",
      "Iterated through 5200 icao names\n",
      "Iterated through 5300 icao names\n",
      "Iterated through 5400 icao names\n",
      "Iterated through 5500 icao names\n",
      "Iterated through 5600 icao names\n",
      "Iterated through 5700 icao names\n",
      "Iterated through 5800 icao names\n",
      "Iterated through 5900 icao names\n",
      "Iterated through 6000 icao names\n",
      "Shape of df_final: (206985, 9)\n",
      "Saved file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def pad_buffered_rows(buffered_rows):\n",
    "    padded_buffered_rows = []\n",
    "    for i in range(BATCH_SIZE - len(buffered_rows)):\n",
    "        padded_buffered_rows.append(buffered_rows[0])\n",
    "    \n",
    "    for row in buffered_rows:\n",
    "        padded_buffered_rows.append(row)\n",
    "    \n",
    "    return padded_buffered_rows\n",
    "\n",
    "# final csv dataframe\n",
    "df_final = pd.DataFrame()\n",
    "\n",
    "iteration = 0\n",
    "# for each unique icao, create CSV for it\n",
    "for name in unique_icao:\n",
    "    # print stats\n",
    "    if iteration % 100 == 0:\n",
    "        print('Iterated through {} icao names'.format(iteration))\n",
    "    iteration +=1\n",
    "    \n",
    "    # get rows where icao == name (boolean vector)\n",
    "    selector = month_df['icao24'] == name\n",
    "    one_plane_df = month_df[selector]\n",
    "    \n",
    "    # Make sure columns have data, otherwise skip plane\n",
    "    if (one_plane_df.isnull().values.any()):\n",
    "        continue\n",
    "    \n",
    "    # List to hold pending rows to add to dataframe\n",
    "    buffered_rows = []\n",
    "    \n",
    "    ## calculate displacement columns\n",
    "    \n",
    "    # add first row with 0s for displacement columns\n",
    "    first_row = one_plane_df.iloc[0]\n",
    "    prev_lat = first_row['lat']\n",
    "    prev_lon = first_row['lon']\n",
    "\n",
    "#     row_prime = pd.DataFrame({\n",
    "#             'time': [first_row['time']], \n",
    "#             'icao24':[first_row['icao24']],\n",
    "#             'lat':[first_row['lat']],\n",
    "#             'lon':[first_row['lon']],\n",
    "#             'x_displacement':[0],\n",
    "#             'y_displacement':[0],\n",
    "#             'velocity':[first_row['velocity']],\n",
    "#             'heading':[first_row['heading']],\n",
    "#             'baroaltitude':[first_row['baroaltitude']]\n",
    "#     })\n",
    "#     buffered_rows.append(row_prime)\n",
    "\n",
    "    # for all except for first row, calculate displacement based on previous row's lat and lon\n",
    "    for index, row in islice(one_plane_df.iterrows(), 1, None):\n",
    "        curr_lat = row['lat']\n",
    "        curr_lon = row['lon']\n",
    "\n",
    "        # compute distance for lat and then lon\n",
    "        x_disp = curr_lon - prev_lon\n",
    "        y_disp = curr_lat - prev_lat\n",
    "\n",
    "        # if zero displacement found, pad and add to df_final\n",
    "        if (x_disp == 0 or y_disp == 0): \n",
    "            # if greater than 2 in buffer, pad and add them all to df_final\n",
    "            if (len(buffered_rows) > 2):\n",
    "                padded_buffered_rows = pad_buffered_rows(buffered_rows)\n",
    "                for row in padded_buffered_rows:    \n",
    "                    df_final = df_final.append(row)\n",
    "            \n",
    "            buffered_rows = []\n",
    "            continue\n",
    "        \n",
    "        # save curr lat and lon as prev for next iteration\n",
    "        prev_lat = curr_lat\n",
    "        prev_lon = curr_lon\n",
    "\n",
    "        # add the row\n",
    "        row_prime = pd.DataFrame({\n",
    "            'time': [row['time']], \n",
    "            'icao24':[row['icao24']],\n",
    "            'lat':[row['lat']],\n",
    "            'lon':[row['lon']],\n",
    "            'x_displacement':[x_disp],\n",
    "            'y_displacement':[y_disp],\n",
    "            'velocity':[row['velocity']],\n",
    "            'heading':[row['heading']],\n",
    "            'baroaltitude':[row['baroaltitude']]\n",
    "        })\n",
    "        buffered_rows.append(row_prime)\n",
    "        \n",
    "        if (len(buffered_rows) >= BATCH_SIZE):\n",
    "            for row in buffered_rows:\n",
    "                df_final = df_final.append(row)\n",
    "            buffered_rows = []\n",
    "        \n",
    "    # if greater than 2 in buffer, pad and add them all to df_final\n",
    "    if (len(buffered_rows) > 2):\n",
    "        padded_buffered_rows = pad_buffered_rows(buffered_rows)\n",
    "        for row in padded_buffered_rows:    \n",
    "            df_final = df_final.append(row)\n",
    "            \n",
    "\n",
    "print('Shape of df_final: {}'.format(df_final.shape))    \n",
    "\n",
    "# write to file\n",
    "\n",
    "clean_dir = 'cleaned/'\n",
    "if not os.path.exists(clean_dir):\n",
    "    os.makedirs(clean_dir)\n",
    "    \n",
    "# write only rows to csv where the vector is true:\n",
    "df_final.to_csv(clean_dir+'{}'.format(filename), index=False)\n",
    "    \n",
    "print('Saved file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmech",
   "language": "python",
   "name": "dmech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
