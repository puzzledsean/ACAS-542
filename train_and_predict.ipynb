{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tyronehou/.virtualenvs/pytorch/lib/python3.6/site-packages/matplotlib/__init__.py:1405: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate data\n",
    "np.random.seed(2)\n",
    "\n",
    "T = 20\n",
    "L = 1000\n",
    "N = 100\n",
    "\n",
    "x = np.empty((N, L), 'int64')\n",
    "x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)\n",
    "data = np.sin(x / 1.0 / T).astype('float64')\n",
    "torch.save(data, open('traindata.pt', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "# Data shape 5 dim vector []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequence model\n",
    "\n",
    "class Sequence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Sequence, self).__init__()\n",
    "        self.lstm1 = nn.LSTMCell(5, 51)\n",
    "        self.lstm2 = nn.LSTMCell(51, 51)\n",
    "        self.linear = nn.Linear(51, 5)\n",
    "\n",
    "    def forward(self, input, future = 0):\n",
    "        outputs = []\n",
    "        h_t = Variable(torch.zeros(input.size(0), 51).double(), requires_grad=False)\n",
    "        c_t = Variable(torch.zeros(input.size(0), 51).double(), requires_grad=False)\n",
    "        h_t2 = Variable(torch.zeros(input.size(0), 51).double(), requires_grad=False)\n",
    "        c_t2 = Variable(torch.zeros(input.size(0), 51).double(), requires_grad=False)\n",
    "\n",
    "        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):\n",
    "            h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs += [output]\n",
    "        for i in range(future):# if we should predict the future\n",
    "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs += [output]\n",
    "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1000)\n"
     ]
    }
   ],
   "source": [
    "# # set random seed to 0\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# # load data and make training set\n",
    "# data = pd.read_csv('NMAC.csv')\n",
    "# print(data['NMAC_id'][5])\n",
    "\n",
    "# # drop unneeded columns to form matrix to be trained on\n",
    "# data_matr = data.drop(['NMAC_id', 'alert_1', 'alert_2', 'onground_1', 'onground_2'], axis=1).as_matrix().astype('float')\n",
    "# print(data_m)\n",
    "\n",
    "data = torch.load('traindata.pt')\n",
    "input = Variable(torch.from_numpy(data[3:, :-1]), requires_grad=False)\n",
    "target = Variable(torch.from_numpy(data[3:, 1:]), requires_grad=False)\n",
    "test_input = Variable(torch.from_numpy(data[:3, :-1]), requires_grad=False)\n",
    "test_target = Variable(torch.from_numpy(data[:3, 1:]), requires_grad=False)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  0\n",
      "97\n",
      "loss: 0.520363350937\n",
      "97\n",
      "loss: 0.512229799748\n",
      "97\n",
      "loss: 0.484058280042\n",
      "97\n",
      "loss: 0.46459071684\n",
      "97\n",
      "loss: 0.374606501428\n",
      "97\n",
      "loss: 26.3772836245\n",
      "97\n",
      "loss: 0.780855096968\n",
      "97\n",
      "loss: 0.222296263572\n",
      "97\n",
      "loss: 0.116127133006\n",
      "97\n",
      "loss: 1.11775618017\n",
      "97\n",
      "loss: 0.0320657779606\n",
      "97\n",
      "loss: 0.0279428710386\n",
      "97\n",
      "loss: 0.0257227341566\n",
      "97\n",
      "loss: 0.0249875217876\n",
      "97\n",
      "loss: 0.0238867195271\n",
      "97\n",
      "loss: 0.0220747701388\n",
      "97\n",
      "loss: 0.0192094236946\n",
      "97\n",
      "loss: 0.015186273865\n",
      "97\n",
      "loss: 0.00750332555625\n",
      "97\n",
      "loss: 0.00597948399276\n",
      "3\n",
      "test loss: 0.00515258112353\n",
      "STEP:  1\n",
      "97\n",
      "loss: 0.00536874418953\n",
      "97\n",
      "loss: 0.00427795478417\n",
      "97\n",
      "loss: 0.00371197449836\n",
      "97\n",
      "loss: 0.00281342929269\n",
      "97\n",
      "loss: 0.00235402156691\n",
      "97\n",
      "loss: 0.00159618217439\n",
      "97\n",
      "loss: 0.000853790467365\n",
      "97\n",
      "loss: 0.000574718243888\n",
      "97\n",
      "loss: 0.000433294890883\n",
      "97\n",
      "loss: 0.000411904923024\n",
      "97\n",
      "loss: 0.000408734000046\n",
      "97\n",
      "loss: 0.000407004469513\n",
      "97\n",
      "loss: 0.000405167915999\n",
      "97\n",
      "loss: 0.000400733640182\n",
      "97\n",
      "loss: 0.000390849500798\n",
      "97\n",
      "loss: 0.000369033067092\n",
      "97\n",
      "loss: 0.000322517308307\n",
      "97\n",
      "loss: 0.000271591402056\n",
      "97\n",
      "loss: 0.000244462376705\n",
      "97\n",
      "loss: 0.000216642458918\n",
      "3\n",
      "test loss: 8.65886050451e-05\n",
      "STEP:  2\n",
      "97\n",
      "loss: 0.000196932650872\n",
      "97\n",
      "loss: 0.000188699446549\n",
      "97\n",
      "loss: 0.000185834169533\n",
      "97\n",
      "loss: 0.000184592454113\n",
      "97\n",
      "loss: 0.000183984867326\n",
      "97\n",
      "loss: 0.000182869977824\n",
      "97\n",
      "loss: 0.000182303110564\n",
      "97\n",
      "loss: 0.000181890481638\n",
      "97\n",
      "loss: 0.000181450217104\n",
      "97\n",
      "loss: 0.000181053530188\n",
      "97\n",
      "loss: 0.000180270752795\n",
      "97\n",
      "loss: 0.000178687319702\n",
      "97\n",
      "loss: 0.000175406340063\n",
      "97\n",
      "loss: 0.00016930852444\n",
      "97\n",
      "loss: 0.000160692432436\n",
      "97\n",
      "loss: 0.000151301758289\n",
      "97\n",
      "loss: 0.000144166536606\n",
      "97\n",
      "loss: 0.000140343239407\n",
      "97\n",
      "loss: 0.000138979400952\n",
      "97\n",
      "loss: 0.000138134684453\n",
      "3\n",
      "test loss: 4.30803639141e-05\n",
      "STEP:  3\n",
      "97\n",
      "loss: 0.000137168232029\n",
      "97\n",
      "loss: 0.0001361376678\n",
      "97\n",
      "loss: 0.000135407086634\n",
      "97\n",
      "loss: 0.000134350201898\n",
      "97\n",
      "loss: 0.000133487812498\n",
      "97\n",
      "loss: 0.000131587661283\n",
      "97\n",
      "loss: 0.000127672485817\n",
      "97\n",
      "loss: 0.00012029736424\n",
      "97\n",
      "loss: 0.000109340386042\n",
      "97\n",
      "loss: 9.77069830806e-05\n",
      "97\n",
      "loss: 8.84666480698e-05\n",
      "97\n",
      "loss: 8.82198198672e-05\n",
      "97\n",
      "loss: 8.07135332507e-05\n",
      "97\n",
      "loss: 7.9263945942e-05\n",
      "97\n",
      "loss: 7.71356575914e-05\n",
      "97\n",
      "loss: 7.52381836789e-05\n",
      "97\n",
      "loss: 7.45864208742e-05\n",
      "97\n",
      "loss: 7.4308478024e-05\n",
      "97\n",
      "loss: 7.36861317136e-05\n",
      "97\n",
      "loss: 7.16850351256e-05\n",
      "3\n",
      "test loss: 3.85570802262e-05\n",
      "STEP:  4\n",
      "97\n",
      "loss: 6.94981070782e-05\n",
      "97\n",
      "loss: 6.67116182336e-05\n",
      "97\n",
      "loss: 6.50965261219e-05\n",
      "97\n",
      "loss: 6.36584169375e-05\n",
      "97\n",
      "loss: 6.16032817094e-05\n",
      "97\n",
      "loss: 5.78459950264e-05\n",
      "97\n",
      "loss: 4.75361699627e-05\n",
      "97\n",
      "loss: 3.99055196226e-05\n",
      "97\n",
      "loss: 4.56770651347e-05\n",
      "97\n",
      "loss: 3.69223258687e-05\n",
      "97\n",
      "loss: 3.05827406646e-05\n",
      "97\n",
      "loss: 2.94454222572e-05\n",
      "97\n",
      "loss: 2.75077068109e-05\n",
      "97\n",
      "loss: 2.66035703996e-05\n",
      "97\n",
      "loss: 2.63878910659e-05\n",
      "97\n",
      "loss: 2.63537068183e-05\n",
      "97\n",
      "loss: 2.63181658319e-05\n",
      "97\n",
      "loss: 2.62464169439e-05\n",
      "97\n",
      "loss: 2.61011684397e-05\n",
      "97\n",
      "loss: 2.58713596678e-05\n",
      "3\n",
      "test loss: 2.42332269006e-05\n",
      "STEP:  5\n",
      "97\n",
      "loss: 2.56632304071e-05\n",
      "97\n",
      "loss: 2.55184850915e-05\n",
      "97\n",
      "loss: 2.53916507415e-05\n",
      "97\n",
      "loss: 2.52859469014e-05\n",
      "97\n",
      "loss: 2.52004274524e-05\n",
      "97\n",
      "loss: 2.50712273389e-05\n",
      "97\n",
      "loss: 2.48599571031e-05\n",
      "97\n",
      "loss: 2.40602730897e-05\n",
      "97\n",
      "loss: 2.1649928665e-05\n",
      "97\n",
      "loss: 1.9004898338e-05\n",
      "97\n",
      "loss: 1.85780689615e-05\n",
      "97\n",
      "loss: 4.02004157825e-05\n",
      "97\n",
      "loss: 1.57252878534e-05\n",
      "97\n",
      "loss: 1.47445749576e-05\n",
      "97\n",
      "loss: 1.43168885052e-05\n",
      "97\n",
      "loss: 1.35358579219e-05\n",
      "97\n",
      "loss: 1.31386438653e-05\n",
      "97\n",
      "loss: 1.26744580235e-05\n",
      "97\n",
      "loss: 1.22010715572e-05\n",
      "97\n",
      "loss: 1.16001271077e-05\n",
      "3\n",
      "test loss: 1.30219701917e-05\n",
      "STEP:  6\n",
      "97\n",
      "loss: 1.12429523048e-05\n",
      "97\n",
      "loss: 1.10016808112e-05\n",
      "97\n",
      "loss: 1.06976514841e-05\n",
      "97\n",
      "loss: 1.0395509986e-05\n",
      "97\n",
      "loss: 1.01799977347e-05\n",
      "97\n",
      "loss: 1.00151618289e-05\n",
      "97\n",
      "loss: 9.52945637637e-06\n",
      "97\n",
      "loss: 9.03244955521e-06\n",
      "97\n",
      "loss: 8.94927259048e-06\n",
      "97\n",
      "loss: 8.25909156291e-06\n",
      "97\n",
      "loss: 8.10661813691e-06\n",
      "97\n",
      "loss: 7.97641146123e-06\n",
      "97\n",
      "loss: 7.87794349151e-06\n",
      "97\n",
      "loss: 7.72030389835e-06\n",
      "97\n",
      "loss: 7.40532628974e-06\n",
      "97\n",
      "loss: 7.20819265663e-06\n",
      "97\n",
      "loss: 7.00846833666e-06\n",
      "97\n",
      "loss: 6.81980481265e-06\n",
      "97\n",
      "loss: 6.79423324023e-06\n",
      "97\n",
      "loss: 6.64794620764e-06\n",
      "3\n",
      "test loss: 9.48559127272e-06\n",
      "STEP:  7\n",
      "97\n",
      "loss: 6.61620367502e-06\n",
      "97\n",
      "loss: 6.55959134578e-06\n",
      "97\n",
      "loss: 6.52674569306e-06\n",
      "97\n",
      "loss: 6.44266179307e-06\n",
      "97\n",
      "loss: 6.33338540695e-06\n",
      "97\n",
      "loss: 6.43632371113e-06\n",
      "97\n",
      "loss: 6.14690602492e-06\n",
      "97\n",
      "loss: 6.06162963162e-06\n",
      "97\n",
      "loss: 1.26960664035e-05\n",
      "97\n",
      "loss: 5.91331315472e-06\n",
      "97\n",
      "loss: 5.85925438224e-06\n",
      "97\n",
      "loss: 5.768716362e-06\n",
      "97\n",
      "loss: 5.53677026862e-06\n",
      "97\n",
      "loss: 5.34886515467e-06\n",
      "97\n",
      "loss: 5.28676514039e-06\n",
      "97\n",
      "loss: 5.24235131241e-06\n",
      "97\n",
      "loss: 5.14193911459e-06\n",
      "97\n",
      "loss: 5.00334865182e-06\n",
      "97\n",
      "loss: 4.94769636686e-06\n",
      "97\n",
      "loss: 5.00324585965e-06\n",
      "3\n",
      "test loss: 7.11979884044e-06\n",
      "STEP:  8\n",
      "97\n",
      "loss: 4.89631818536e-06\n",
      "97\n",
      "loss: 4.88531893965e-06\n",
      "97\n",
      "loss: 4.87601396232e-06\n",
      "97\n",
      "loss: 4.85311949059e-06\n",
      "97\n",
      "loss: 4.83266260522e-06\n",
      "97\n",
      "loss: 4.822444194e-06\n",
      "97\n",
      "loss: 4.81605579366e-06\n",
      "97\n",
      "loss: 4.81197927634e-06\n",
      "97\n",
      "loss: 4.80892312926e-06\n",
      "97\n",
      "loss: 4.80517699591e-06\n",
      "97\n",
      "loss: 4.79793079504e-06\n",
      "97\n",
      "loss: 4.7817269907e-06\n",
      "97\n",
      "loss: 4.74893548743e-06\n",
      "97\n",
      "loss: 4.70470663601e-06\n",
      "97\n",
      "loss: 4.65126408914e-06\n",
      "97\n",
      "loss: 4.63290422513e-06\n",
      "97\n",
      "loss: 4.61829312231e-06\n",
      "97\n",
      "loss: 4.61614491312e-06\n",
      "97\n",
      "loss: 4.61530194863e-06\n",
      "3\n",
      "test loss: 7.38480822196e-06\n",
      "STEP:  9\n",
      "97\n",
      "loss: 4.61530194863e-06\n",
      "97\n",
      "loss: 4.61489283444e-06\n",
      "3\n",
      "test loss: 7.37612610541e-06\n",
      "STEP:  10\n",
      "97\n",
      "loss: 4.61489283444e-06\n",
      "97\n",
      "loss: 4.61290675012e-06\n",
      "97\n",
      "loss: 4.6041444104e-06\n",
      "97\n",
      "loss: 4.59362679602e-06\n",
      "97\n",
      "loss: 4.57177253368e-06\n",
      "97\n",
      "loss: 4.52950234879e-06\n",
      "97\n",
      "loss: 4.44876052323e-06\n",
      "97\n",
      "loss: 4.33279834261e-06\n",
      "97\n",
      "loss: 0.000116032690204\n",
      "97\n",
      "loss: 4.46921779685e-06\n",
      "97\n",
      "loss: 4.10541018451e-06\n",
      "97\n",
      "loss: 4.06933889049e-06\n",
      "97\n",
      "loss: 4.06086872928e-06\n",
      "97\n",
      "loss: 4.04305477285e-06\n",
      "97\n",
      "loss: 4.03645689793e-06\n",
      "97\n",
      "loss: 4.02570809719e-06\n",
      "97\n",
      "loss: 4.02080504168e-06\n",
      "97\n",
      "loss: 4.01928482969e-06\n",
      "97\n",
      "loss: 4.01861130463e-06\n",
      "3\n",
      "test loss: 6.95181060611e-06\n",
      "STEP:  11\n",
      "97\n",
      "loss: 4.01861130463e-06\n",
      "97\n",
      "loss: 4.01803777154e-06\n",
      "3\n",
      "test loss: 6.94998972913e-06\n",
      "STEP:  12\n",
      "97\n",
      "loss: 4.01803777154e-06\n",
      "97\n",
      "loss: 4.01735975258e-06\n",
      "3\n",
      "test loss: 6.95229187347e-06\n",
      "STEP:  13\n",
      "97\n",
      "loss: 4.01735975258e-06\n",
      "97\n",
      "loss: 4.01645876826e-06\n",
      "3\n",
      "test loss: 6.95802521044e-06\n",
      "STEP:  14\n",
      "97\n",
      "loss: 4.01645876826e-06\n",
      "97\n",
      "loss: 4.01534474244e-06\n",
      "97\n",
      "loss: 4.01432335234e-06\n",
      "97\n",
      "loss: 4.01317626593e-06\n",
      "97\n",
      "loss: 4.01182687313e-06\n",
      "97\n",
      "loss: 4.01074049383e-06\n",
      "97\n",
      "loss: 4.00873589963e-06\n",
      "97\n",
      "loss: 4.00454746109e-06\n",
      "97\n",
      "loss: 3.99500336697e-06\n",
      "97\n",
      "loss: 3.96799146741e-06\n",
      "97\n",
      "loss: 3.99417693594e-06\n",
      "97\n",
      "loss: 3.90144896322e-06\n",
      "97\n",
      "loss: 3.87041508848e-06\n",
      "97\n",
      "loss: 4.21579449934e-06\n",
      "97\n",
      "loss: 3.83480345265e-06\n",
      "97\n",
      "loss: 3.83183152978e-06\n",
      "97\n",
      "loss: 3.82652384138e-06\n",
      "97\n",
      "loss: 3.82115259155e-06\n",
      "97\n",
      "loss: 3.8150942592e-06\n",
      "97\n",
      "loss: 3.80938370179e-06\n",
      "3\n",
      "test loss: 6.47937564427e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# build the model\n",
    "seq = Sequence()\n",
    "seq.double()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# use LBFGS as optimizer since we can load the whole data to train\n",
    "optimizer = optim.LBFGS(seq.parameters(), lr=0.8)\n",
    "\n",
    "# begin to train\n",
    "for i in range(15):\n",
    "    print('STEP: ', i)\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        out = seq(input)\n",
    "        loss = criterion(out, target)\n",
    "        print('loss:', loss.data.numpy()[0])\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    optimizer.step(closure)\n",
    "    \n",
    "    # begin to predict\n",
    "    future = 6\n",
    "    pred = seq(test_input, future = future)\n",
    "    loss = criterion(pred[:, :-future], test_target)\n",
    "    print('test loss:', loss.data.numpy()[0])\n",
    "    y = pred.data.numpy()\n",
    "    \n",
    "#     # draw the result\n",
    "#     plt.figure(figsize=(30,10))\n",
    "#     plt.title('Predict future values for time sequences\\n(Dashlines are predicted values)', fontsize=30)\n",
    "#     plt.xlabel('x', fontsize=20)\n",
    "#     plt.ylabel('y', fontsize=20)\n",
    "#     plt.xticks(fontsize=20)\n",
    "#     plt.yticks(fontsize=20)\n",
    "#     def draw(yi, color):\n",
    "#         plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)\n",
    "#         plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)\n",
    "#     draw(y[0], 'r')\n",
    "#     draw(y[1], 'g')\n",
    "#     draw(y[2], 'b')\n",
    "#     plt.savefig('predict%d.pdf'%i)\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
